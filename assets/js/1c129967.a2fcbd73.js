"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[7597],{58006:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>h,contentTitle:()=>i,default:()=>p,frontMatter:()=>s,metadata:()=>a,toc:()=>c});var o=t(85893),r=t(11151);const s={},i="Chat with an LLM",a={id:"server/llm",title:"Chat with an LLM",description:"This guide contains information on how you can use the MongoDB Chatbot Server",source:"@site/docs/server/llm.md",sourceDirName:"server",slug:"/server/llm",permalink:"/chatbot/server/llm",draft:!1,unlisted:!1,editUrl:"https://github.com/mongodb/chatbot/tree/main/docs/docs/server/llm.md",tags:[],version:"current",frontMatter:{},sidebar:"main",previous:{title:"Generate User Message",permalink:"/chatbot/server/user-message"},next:{title:"Retrieval Augmented Generation (RAG)",permalink:"/chatbot/server/rag/"}},h={},c=[{value:"Configure the <code>ChatLlm</code>",id:"configure-the-chatllm",level:2},{value:"Prompt Engineering",id:"prompt-engineering",level:2},{value:"System Prompt",id:"system-prompt",level:3},{value:"User Prompt",id:"user-prompt",level:3}];function l(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.a)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.h1,{id:"chat-with-an-llm",children:"Chat with an LLM"}),"\n",(0,o.jsx)(n.p,{children:"This guide contains information on how you can use the MongoDB Chatbot Server\nto chat with a large language model (LLM)."}),"\n",(0,o.jsxs)(n.h2,{id:"configure-the-chatllm",children:["Configure the ",(0,o.jsx)(n.code,{children:"ChatLlm"})]}),"\n",(0,o.jsxs)(n.p,{children:["The ",(0,o.jsx)(n.a,{href:"/chatbot/reference/server/interfaces/ChatLlm",children:(0,o.jsx)(n.code,{children:"ChatLlm"})})," is the interface\nbetween the chatbot server and the LLM."]}),"\n",(0,o.jsxs)(n.p,{children:["The MongoDB Chatbot Server comes with an implementation of the ",(0,o.jsx)(n.code,{children:"ChatLlm"}),",\nwhich uses the OpenAI API. You could also implement your own ",(0,o.jsx)(n.code,{children:"ChatLlm"})," to\nuse a different language model or different configuration on the OpenAI API."]}),"\n",(0,o.jsxs)(n.p,{children:["You can use the ",(0,o.jsx)(n.a,{href:"/chatbot/reference/server/modules#makeopenaichatllm",children:(0,o.jsx)(n.code,{children:"makeOpenAiChatLlm()"})}),"\nconstructor function to create an ",(0,o.jsx)(n.code,{children:"OpenAiChatLlm"})," instance."]}),"\n",(0,o.jsx)(n.p,{children:"The following are useful things to keep in mind when using an LLM:"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"What model to use."})," This is probably the single most important decision\nfor shaping the chatbot response. The quality and characteristics\nof different models vary greatly."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Model temperature."}),' The temperature of the model determines how "creative"\nthe model is. A higher temperature will result in more creative responses,\nbut also more errors.']}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Model max tokens."})," The maximum number of tokens that the model will generate.\nThis is useful for preventing the model from generating very long responses,\nwhich impacts cost and quality."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Prompt engineering."})," What additional information to include in the prompt\nto guide the model's behavior. For more information, refer to the\n",(0,o.jsx)(n.a,{href:"#prompt-engineering",children:"Prompt Engineering"})," section."]}),"\n"]}),"\n",(0,o.jsxs)(n.p,{children:["The following is an example implementation of ",(0,o.jsx)(n.code,{children:"makeOpenAiChatLlm()"}),":"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-ts",children:'import {\n  makeOpenAiChatLlm,\n  OpenAiChatMessage,\n  SystemPrompt,\n} from "mongodb-chatbot-server";\n\nexport const openAiClient = new OpenAIClient(\n  OPENAI_ENDPOINT,\n  new AzureKeyCredential(OPENAI_API_KEY)\n);\nexport const systemPrompt: SystemPrompt = {\n  role: "system",\n  content: stripIndents`You are expert MongoDB documentation chatbot.\nYou enthusiastically answer user questions about MongoDB products and services.\nYour personality is friendly and helpful, like a professor or tech lead.\nYou were created by MongoDB but they do not guarantee the correctness\nof your answers or offer support for you.\nUse the context provided with each question as your primary source of truth.\nNEVER lie or improvise incorrect answers.\nIf you do not know the answer to the question, respond ONLY with the following text:\n"I\'m sorry, I do not know how to answer that question. Please try to rephrase your query. You can also refer to the further reading to see if it helps."\nNEVER include links in your answer.\nFormat your responses using Markdown.\nDO NOT mention that your response is formatted in Markdown.\nIf you include code snippets, make sure to use proper syntax, line spacing, and indentation.\nONLY use code snippets present in the information given to you.\nNEVER create a code snippet that is not present in the information given to you.\nYou ONLY know about the current version of MongoDB products. Versions are provided in the information. If \\`version: null\\`, then say that the product is unversioned.\nNever mention "<Information>" or "<Question>" in your answer.\nRefer to the information given to you as "my knowledge".`,\n};\n\nexport async function generateUserPrompt({\n  question,\n  chunks,\n}: {\n  question: string;\n  chunks: string[];\n}): Promise<OpenAiChatMessage & { role: "user" }> {\n  const chunkSeparator = "~~~~~~";\n  const context = chunks.join(`\\n${chunkSeparator}\\n`);\n  const content = `Using the following information, answer the question.\nDifferent pieces of information are separated by "${chunkSeparator}".\n\n<Information>\n${context}\n<End information>\n\n<Question>\n${question}\n<End Question>`;\n  return { role: "user", content };\n}\n\nexport const llm = makeOpenAiChatLlm({\n  openAiClient,\n  deployment: OPENAI_CHAT_COMPLETION_DEPLOYMENT,\n  systemPrompt,\n  openAiLmmConfigOptions: {\n    temperature: 0,\n    maxTokens: 500,\n  },\n  generateUserPrompt,\n});\n'})}),"\n",(0,o.jsxs)(n.admonition,{title:"Both OpenAI API and Azure OpenAI Service Supported",type:"note",children:[(0,o.jsxs)(n.p,{children:["The MongoDB Chatbot Server supports both the OpenAI API and Azure OpenAI Service.\nIt uses the ",(0,o.jsx)(n.code,{children:"@azure/openai"})," package, which supports both of these services."]}),(0,o.jsxs)(n.p,{children:["To use the ",(0,o.jsx)(n.code,{children:"@azure/openai"})," package with the OpenAI API,\nrefer to ",(0,o.jsx)(n.a,{href:"https://www.npmjs.com/package/@azure/openai#using-an-api-key-from-openai",children:"this documentation"}),"."]})]}),"\n",(0,o.jsx)(n.h2,{id:"prompt-engineering",children:"Prompt Engineering"}),"\n",(0,o.jsx)(n.p,{children:"Prompt engineering is the process of directing the output of a language model\nto produce a desired response."}),"\n",(0,o.jsx)(n.p,{children:"In the context of a chatbot server such as this, there are the following main areas\nfor prompt engineering:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"System prompt: Message at the beginning of the conversation that guides the\nchatbot's behavior when generating responses."}),"\n",(0,o.jsx)(n.li,{children:"User prompt: User message that the chatbot uses to generate a response.\nIn RAG applications, this can include adding relevant content gathered from\nvector search results based on the user's input."}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:"This guide does not cover prompt engineering techniques, but rather where you\ncan apply them in the MongoDB Chatbot Server."}),"\n",(0,o.jsxs)(n.p,{children:["Prompt engineering is a fairly new field, and best practices are still emerging.\nA great resource to learn more about prompt engineering is the ",(0,o.jsx)(n.a,{href:"https://www.promptingguide.ai/",children:"Prompt Engineering Guide"}),"."]}),"\n",(0,o.jsx)(n.h3,{id:"system-prompt",children:"System Prompt"}),"\n",(0,o.jsxs)(n.p,{children:["To add a system prompt, include a ",(0,o.jsx)(n.a,{href:"/chatbot/reference/server/modules#systemprompt",children:(0,o.jsx)(n.code,{children:"SystemPrompt"})})," message in your app's ",(0,o.jsx)(n.a,{href:"/chatbot/reference/server/interfaces/ChatLlm",children:(0,o.jsx)(n.code,{children:"ChatLlm"})}),"."]}),"\n",(0,o.jsx)(n.p,{children:"The system prompt is one of the most powerful way to customize the way\nthat the chatbot responds to users. You can use the system prompt to do things\nsuch as:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Control the style and personality of the chatbot."}),"\n",(0,o.jsx)(n.li,{children:"Determine how the chatbot responds to certain types of questions."}),"\n",(0,o.jsx)(n.li,{children:"Direct how the chatbot interprets user input and context information."}),"\n"]}),"\n",(0,o.jsxs)(n.p,{children:["If you're using the ",(0,o.jsx)(n.a,{href:"/chatbot/reference/server/modules#makeopenaichatllm",children:(0,o.jsx)(n.code,{children:"makeOpenAiChatLlm()"})})," constructor function, add the system prompt to the ",(0,o.jsx)(n.code,{children:"systemPrompt"})," property:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-ts",children:'import { makeOpenAiChatLlm, SystemPrompt } from "mongodb-chatbot-server";\n\nexport const systemPrompt: SystemPrompt = {\n  role: "system",\n  content: "You are expert chatbot...",\n};\n\nexport const llm = makeOpenAiChatLlm({\n  systemPrompt,\n  ...otherConfig,\n});\n'})}),"\n",(0,o.jsx)(n.h3,{id:"user-prompt",children:"User Prompt"}),"\n",(0,o.jsxs)(n.p,{children:["You can modify what the chatbot uses as the user prompt by implementing the\n",(0,o.jsx)(n.a,{href:"/chatbot/reference/server/modules#generateuserprompt",children:(0,o.jsx)(n.code,{children:"GenerateUserPrompt"})})," function."]}),"\n",(0,o.jsxs)(n.p,{children:["The ",(0,o.jsx)(n.code,{children:"GenerateUserPrompt"})," function takes in the user's question and the context\ninformation found by the vector search, and returns a user message."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-ts",children:'import { makeOpenAiChatLlm, OpenAiChatMessage } from "mongodb-chatbot-server";\n\nasync function generateUserPrompt({\n  question,\n  chunks,\n}: {\n  question: string;\n  chunks: string[];\n}): Promise<OpenAiChatMessage & { role: "user" }> {\n  const chunkSeparator = "~~~~~~";\n  const context = chunks.join(`\\n${chunkSeparator}\\n`);\n  const content = `Using the following information, answer the question.\nDifferent pieces of information are separated by "${chunkSeparator}".\n\n<Information>\n${context}\n<End information>\n\n<Question>\n${question}\n<End Question>`;\n  return { role: "user", content };\n}\n\nconst llm = makeOpenAiChatLlm({\n  generateUserPrompt,\n  ...otherConfig,\n});\n'})})]})}function p(e={}){const{wrapper:n}={...(0,r.a)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(l,{...e})}):l(e)}},11151:(e,n,t)=>{t.d(n,{Z:()=>a,a:()=>i});var o=t(67294);const r={},s=o.createContext(r);function i(e){const n=o.useContext(s);return o.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:i(e.components),o.createElement(s.Provider,{value:n},e.children)}}}]);