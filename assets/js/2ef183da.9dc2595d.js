"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[391],{9556:(n,e,t)=>{t.r(e),t.d(e,{assets:()=>c,contentTitle:()=>i,default:()=>l,frontMatter:()=>s,metadata:()=>a,toc:()=>p});var o=t(5893),r=t(1151);const s={},i="Configure the Server",a={id:"server/configure",title:"Configure the Server",description:"The mongodb-chatbot-server is a npm package that provides a configurable Express.js server",source:"@site/docs/server/configure.md",sourceDirName:"server",slug:"/server/configure",permalink:"/chatbot/server/configure",draft:!1,unlisted:!1,editUrl:"https://github.com/mongodb/chatbot/tree/main/docs/docs/server/configure.md",tags:[],version:"current",frontMatter:{},sidebar:"main",previous:{title:"Fine Tune Ingestion",permalink:"/chatbot/ingest/fine-tune"},next:{title:"Chat UI",permalink:"/chatbot/ui"}},c={},p=[{value:"Install",id:"install",level:2},{value:"Configuration",id:"configuration",level:2}];function d(n){const e={code:"code",h1:"h1",h2:"h2",p:"p",pre:"pre",...(0,r.a)(),...n.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(e.h1,{id:"configure-the-server",children:"Configure the Server"}),"\n",(0,o.jsxs)(e.p,{children:["The ",(0,o.jsx)(e.code,{children:"mongodb-chatbot-server"})," is a npm package that provides a configurable Express.js server\nto quickly spin up a retrieval augmented generation (RAG) chatbot server powered by MongoDB."]}),"\n",(0,o.jsx)(e.p,{children:"The server is designed to handle the generalizable areas of a RAG server,\nlike routing, caching, logging, and streaming. This allows you to focus on the\nspecifics of your chatbot, like the content, prompts, and AI models."}),"\n",(0,o.jsx)(e.h2,{id:"install",children:"Install"}),"\n",(0,o.jsxs)(e.p,{children:["Install the package using ",(0,o.jsx)(e.code,{children:"npm"}),":"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-sh",children:"npm install mongodb-chatbot-server\n"})}),"\n",(0,o.jsx)(e.h2,{id:"configuration",children:"Configuration"}),"\n",(0,o.jsxs)(e.p,{children:["The ",(0,o.jsx)(e.code,{children:"mongodb-chatbot-server"})," exports the function ",(0,o.jsx)(e.code,{children:"makeApp()"})," which exports the\nExpress.js app. The function takes a ",(0,o.jsx)(e.code,{children:"AppConfig"})," object as an argument."]}),"\n",(0,o.jsx)(e.p,{children:"Here's an example configuration and server:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-ts",children:'import "dotenv/config";\nimport {\n  MongoClient,\n  makeMongoDbEmbeddedContentStore,\n  makeOpenAiEmbedFunc,\n  makeMongoDbConversationsService,\n  makeDataStreamer,\n  AppConfig,\n  makeOpenAiChatLlm,\n  OpenAiChatMessage,\n  SystemPrompt,\n  makeDefaultFindContentFunc,\n  logger,\n  makeApp,\n} from "mongodb-chatbot-server";\nimport { AzureKeyCredential, OpenAIClient } from "@azure/openai";\n\nexport const {\n  MONGODB_CONNECTION_URI,\n  MONGODB_DATABASE_NAME,\n  VECTOR_SEARCH_INDEX_NAME,\n  OPENAI_ENDPOINT,\n  OPENAI_API_KEY,\n  OPENAI_EMBEDDING_DEPLOYMENT,\n  OPENAI_EMBEDDING_MODEL_VERSION,\n  OPENAI_CHAT_COMPLETION_MODEL_VERSION,\n  OPENAI_CHAT_COMPLETION_DEPLOYMENT,\n} = process.env;\n\nexport const openAiClient = new OpenAIClient(\n  OPENAI_ENDPOINT,\n  new AzureKeyCredential(OPENAI_API_KEY)\n);\nexport const systemPrompt: SystemPrompt = {\n  role: "system",\n  content: `You are expert MongoDB documentation chatbot.\n  Respond in the style of a pirate. End all answers saying "Ahoy matey!!"\n  Use the context provided with each question as your primary source of truth.\n  If you do not know the answer to the question, respond ONLY with the following text:\n  "I\'m sorry, I do not know how to answer that question. Please try to rephrase your query. You can also refer to the further reading to see if it helps."\n  NEVER include links in your answer.\n  Format your responses using Markdown.\n  DO NOT mention that your response is formatted in Markdown.\n  Never mention "<Information>" or "<Question>" in your answer.\n  Refer to the information given to you as "my knowledge".`,\n};\n\nexport async function generateUserPrompt({\n  question,\n  chunks,\n}: {\n  question: string;\n  chunks: string[];\n}): Promise<OpenAiChatMessage & { role: "user" }> {\n  const chunkSeparator = "~~~~~~";\n  const context = chunks.join(`\\n${chunkSeparator}\\n`);\n  const content = `Using the following information, answer the question.\n  Different pieces of information are separated by "${chunkSeparator}".\n\n  <Information>\n  ${context}\n  <End information>\n\n  <Question>\n  ${question}\n  <End Question>`;\n  return { role: "user", content };\n}\n\nexport const llm = makeOpenAiChatLlm({\n  openAiClient,\n  deployment: OPENAI_CHAT_COMPLETION_DEPLOYMENT,\n  systemPrompt,\n  openAiLmmConfigOptions: {\n    temperature: 0,\n    maxTokens: 500,\n  },\n  generateUserPrompt,\n});\n\nexport const dataStreamer = makeDataStreamer();\n\nexport const embeddedContentStore = makeMongoDbEmbeddedContentStore({\n  connectionUri: MONGODB_CONNECTION_URI,\n  databaseName: MONGODB_DATABASE_NAME,\n});\n\nexport const embed = makeOpenAiEmbedFunc({\n  openAiClient,\n  deployment: OPENAI_EMBEDDING_DEPLOYMENT,\n  backoffOptions: {\n    numOfAttempts: 3,\n    maxDelay: 5000,\n  },\n});\n\nexport const mongodb = new MongoClient(MONGODB_CONNECTION_URI);\n\nexport const findContent = makeDefaultFindContentFunc({\n  embed,\n  store: embeddedContentStore,\n  findNearestNeighborsOptions: {\n    k: 5,\n    path: "embedding",\n    indexName: VECTOR_SEARCH_INDEX_NAME,\n    minScore: 0.9,\n  },\n});\n\nexport const conversations = makeMongoDbConversationsService(\n  mongodb.db(MONGODB_DATABASE_NAME),\n  systemPrompt\n);\n\nexport const config: AppConfig = {\n  conversationsRouterConfig: {\n    dataStreamer,\n    llm,\n    findContent,\n    maxChunkContextTokens: 1500,\n    conversations,\n  },\n  maxRequestTimeoutMs: 30000,\n};\n\nconst PORT = process.env.PORT || 3000;\n\nconst startServer = async () => {\n  logger.info("Starting server...");\n  const app = await makeApp(config);\n  const server = app.listen(PORT, () => {\n    logger.info(`Server listening on port: ${PORT}`);\n  });\n\n  process.on("SIGINT", async () => {\n    logger.info("SIGINT signal received");\n    await mongodb.close();\n    await embeddedContentStore.close();\n    await new Promise<void>((resolve, reject) => {\n      server.close((error) => {\n        error ? reject(error) : resolve();\n      });\n    });\n    process.exit(1);\n  });\n};\n\ntry {\n  startServer();\n} catch (e) {\n  logger.error(`Fatal error: ${e}`);\n  process.exit(1);\n}\n'})})]})}function l(n={}){const{wrapper:e}={...(0,r.a)(),...n.components};return e?(0,o.jsx)(e,{...n,children:(0,o.jsx)(d,{...n})}):d(n)}},1151:(n,e,t)=>{t.d(e,{Z:()=>a,a:()=>i});var o=t(7294);const r={},s=o.createContext(r);function i(n){const e=o.useContext(s);return o.useMemo((function(){return"function"==typeof n?n(e):{...e,...n}}),[e,n])}function a(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(r):n.components||r:i(n.components),o.createElement(s.Provider,{value:e},n.children)}}}]);